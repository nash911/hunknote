# Integration Tests — Compose Coherence

This module contains **live LLM integration tests** that evaluate the coherence
of commit plans generated by `hunknote compose`. Unlike the unit tests under
`tests/`, these make **real API calls** to LLM providers and verify that the
model correctly groups causally dependent changes into the same commit.

> **These are not unit tests.** They require a valid API key and will incur
> token usage costs. They are not part of the `pytest` suite and must be run
> manually.

---

## Background

### The Coherence Problem

`hunknote compose` asks an LLM to split a set of staged changes (hunks) into
a series of atomic commits. The key requirement is that **every intermediate
commit must leave the codebase in a valid state** — no broken imports, no
failing tests, no missing dependencies.

This is hard because the LLM tends to group hunks by *file* or *change type*
(feat, fix, test, docs), which can split **causally dependent changes** across
commits. For example:

```
C3: feat(config): Change default PPO configuration values
    hunks: H4 (config.py), H5 (config.py)

C4: test(config): Update tests for new defaults
    hunks: H6 (test_config.py), H7 (test_config.py)
```

If C3 is committed without C4, the test suite breaks. These should be a
**single commit**.

### Implemented Strategies

The coherence problem is addressed through two complementary strategies
(see `docs/compose_coherence_strategy.md` for full details):

**Strategy 1 — Prompt-Level Coherence Rule**

A rule added to the compose system prompt that explicitly instructs the LLM:

> *If a change in one file requires a corresponding change in another file to
> keep the codebase valid, those hunks MUST be in the same commit.*

**Strategy 2 — File-Relationship Hints (`[FILE RELATIONSHIPS]`)**

Before sending the diff inventory to the LLM, hunknote detects actual
import/dependency relationships between the changed files and includes them
in the prompt:

```
[FILE RELATIONSHIPS]
Detected import dependencies between changed files:
  - tests/test_config.py imports src/config.py  (direct)
  - src/api/client.py imports src/api/schema.py  (direct)
  - tests/test_api.py depends on src/api/schema.py  (transitive, via src/api/client.py)
```

Detection uses a tiered approach:

| Tier | Method | Language Support |
|------|--------|-----------------|
| **Tier 1** | Python `ast` module | Python — 100% accurate |
| **Tier 1.5** | Re-export tracing (`__init__.py`, `index.ts`) | Python, JS/TS |
| **Tier 2** | Regex-based import extraction | JS/TS, Go, Rust, Java, Ruby, C/C++ |
| **Tier 3** | Path heuristics (test file pairing, mirror paths) | All languages |

---

## Directory Structure

```
integration_tests/
├── README.md                        # This file
├── test_compose_coherence.py        # Main evaluation harness
├── test_reexport_coherence.py       # Focused re-export gap tests (legacy)
├── data/                            # JSON test case definitions
│   ├── py_remove_func_test_import.json
│   ├── ts_change_interface_barrel.json
│   ├── go_grpc_circular_3_service_rename.json
│   └── ...  (27 test cases)
└── evals/                           # Timestamped evaluation results
    ├── .gitkeep
    ├── 20260227_141920/
    │   ├── summary.json
    │   ├── python_remove_function_test_import.json
    │   └── ...
    └── ...
```

---

## Test Case Format

Each test case is a JSON file under `data/` with this structure:

```json
{
  "id": "py_remove_func_test_import",
  "language": "python",
  "name": "Python: Remove function + update test import",
  "description": "global_config.py removes get_credentials_file_path(). ...",
  "difficulty": "medium",
  "category": "function_removal",
  "num_files": 2,
  "num_hunks": 4,
  "file_diffs": [
    {
      "file_path": "myapp/global_config.py",
      "hunks": [
        {"hunk_id": "H1_a1b2c3", "header": "@@ -10,8 +10,5 @@", "content": "..."}
      ]
    }
  ],
  "file_relationships": [
    {"source": "tests/test_global_config.py", "target": "myapp/global_config.py", "kind": "direct"}
  ],
  "must_be_together": [
    ["myapp/global_config.py", "tests/test_global_config.py"]
  ],
  "must_be_ordered": [],
  "hunk_to_file": {
    "H1_a1b2c3": "myapp/global_config.py",
    "H4_j0k1l2": "tests/test_global_config.py"
  }
}
```

### Key Fields

| Field | Description |
|-------|-------------|
| `file_diffs` | Synthetic unified diffs with hunk IDs — fed to `build_compose_prompt()` |
| `file_relationships` | Pre-computed `FileRelationship` objects — passed to the prompt builder |
| `must_be_together` | **Coherence assertion**: sets of files that must share at least one commit |
| `must_be_ordered` | **Ordering assertion**: `[A, B]` means A's commit must come at or before B's |
| `hunk_to_file` | Maps each hunk ID to its file — used during coherence checking |
| `difficulty` | `easy`, `medium`, `hard`, `very_hard`, `super_hard`, or `hyper_hard` |

### Coherence Check Logic

For each `must_be_together` group, the harness verifies that there exists **at
least one commit** in the generated plan that contains **all files** in the
group. If the files are split across different commits with no overlap, the
test **fails**.

For each `must_be_ordered` pair `[A, B]`, the harness verifies that the
earliest commit containing file A appears at or before the earliest commit
containing file B.

---

## Test Case Inventory

### By Language

| Language | Count | Difficulties |
|----------|:-----:|--------------|
| Python | 13 | medium (2), hard (4), very_hard (1), super_hard (4), hyper_hard (2) |
| TypeScript | 6 | medium (1), hard (2), super_hard (2), hyper_hard (1) |
| Go | 4 | medium (1), very_hard (1), super_hard (1), hyper_hard (1) |
| Rust | 1 | medium |
| Java | 1 | medium |
| Ruby | 1 | medium |
| C | 1 | medium |

### By Difficulty

| Difficulty | Count | Scale |
|------------|:-----:|-------|
| `medium` | 8 | 2–3 files, 2–4 hunks — basic rename/removal |
| `hard` | 6 | 2–4 files, 3–7 hunks — transitive chains, multi-consumer |
| `very_hard` | 2 | 4–6 files, 5–10 hunks — mixed features, struct changes |
| `super_hard` | 7 | 6–8 files, 11–16 hunks — cascading renames, interleaved groups |
| `hyper_hard` | 4 | 20–40 files, 45–125 hunks — monorepo-scale refactors |

### Full Listing

| ID | Language | Difficulty | Files | Hunks | Name |
|----|----------|------------|:-----:|:-----:|------|
| `c_change_struct_header` | C | medium | 3 | 4 | Change struct in header + update source files |
| `go_rename_interface_method` | Go | medium | 3 | 3 | Rename interface method + update impls |
| `go_add_field_proto_handler_test` | Go | very_hard | 4 | 5 | Add field to struct + handler + test |
| `go_bidirectional_rename_with_tests` | Go | super_hard | 6 | 12 | Bidirectional renames across packages + tests |
| `go_grpc_circular_3_service_rename` | Go | hyper_hard | 20 | 45 | gRPC 3-service circular rename |
| `java_rename_method_impl_test` | Java | medium | 3 | 4 | Rename method in interface + impl + test |
| `py_remove_func_test_import` | Python | medium | 2 | 4 | Remove function + update test import |
| `py_rename_func_across_files` | Python | medium | 3 | 4 | Rename function across 3 files |
| `py_add_required_param_reexport` | Python | hard | 2 | 3 | Add required param via `__init__.py` re-export |
| `py_three_file_transitive_chain` | Python | hard | 3 | 3 | 3-file transitive chain (schema → serializer → endpoint) |
| `py_two_independent_features` | Python | hard | 4 | 5 | Two independent features interleaved |
| `py_rename_exception_multi_consumer` | Python | hard | 4 | 7 | Rename exception class across 4 files |
| `py_mixed_feature_refactor_docstring` | Python | very_hard | 6 | 10 | Mixed feature + refactor + docstrings |
| `py_base_class_change_subclasses_tests` | Python | super_hard | 6 | 11 | Base class constructor change + subclasses + tests |
| `py_keyring_migration_real_world` | Python | super_hard | 7 | 12 | Keyring migration — source + test + docstrings |
| `py_three_coupled_groups_with_noise` | Python | super_hard | 8 | 13 | 3 coupled feature groups + noise docs |
| `py_enum_change_cascade_with_config` | Python | super_hard | 8 | 16 | Enum rename cascading through 5 consumers + config |
| `py_large_refactor_class_rename_20_consumers` | Python | hyper_hard | 40 | 125 | Cascading multi-layer refactor |
| `py_microservices_5_rename_chains` | Python | hyper_hard | 40 | 116 | 5 microservice cascading renames |
| `ruby_rename_method_spec` | Ruby | medium | 3 | 4 | Rename method + update spec and caller |
| `rust_rename_trait_method` | Rust | medium | 3 | 4 | Rename trait method + update impl and caller |
| `ts_change_interface_barrel` | TypeScript | medium | 2 | 2 | Change interface via `index.ts` barrel export |
| `ts_react_context_provider_consumer` | TypeScript | hard | 3 | 4 | React context shape change + provider + consumer |
| `ts_two_coupled_pairs_interleaved` | TypeScript | hard | 4 | 4 | Two coupled pairs interleaved |
| `ts_api_migration_multi_consumer_test` | TypeScript | super_hard | 7 | 14 | API migration — rename + 3 consumers + 3 tests |
| `ts_schema_migration_full_stack` | TypeScript | super_hard | 8 | 14 | Schema migration — model + routes + seed + migration + tests |
| `ts_monorepo_type_rename_cascade` | TypeScript | hyper_hard | 26 | 53 | Monorepo type rename across 4 packages |

---

## Running Tests

### Prerequisites

- A valid API key stored in the system keychain (see `hunknote config --set-key`)
- The `hunknote` package installed in the current environment

### Basic Usage

```bash
# Run all 27 test cases with default provider (Google Gemini 2.5 Flash)
python integration_tests/test_compose_coherence.py

# Use a specific provider and model
python integration_tests/test_compose_coherence.py --provider google --model gemini-2.5-flash
python integration_tests/test_compose_coherence.py --provider anthropic --model claude-sonnet-4-20250514

# Run a single test case by ID
python integration_tests/test_compose_coherence.py --case py_remove_func_test_import

# Filter by language
python integration_tests/test_compose_coherence.py --language python
python integration_tests/test_compose_coherence.py --language typescript

# Filter by difficulty level
python integration_tests/test_compose_coherence.py --diff_level medium
python integration_tests/test_compose_coherence.py --diff_level hyper_hard

# List all available test cases
python integration_tests/test_compose_coherence.py --list
```

### Re-Export Coherence Tests (Legacy)

```bash
# Focused tests for the re-export package gap (Tier 1.5)
python integration_tests/test_reexport_coherence.py
```

These are an earlier, standalone set of tests created to discover and
validate the re-export tracing feature. They are kept for reference but the
main evaluation harness (`test_compose_coherence.py`) supersedes them with
more comprehensive coverage.

---

## Evaluation Results

Each run saves detailed results under `evals/<timestamp>/`:

```
evals/20260227_175926/
├── summary.json                                 # Overall pass rate, token usage, by-language/difficulty breakdown
├── py_remove_func_test_import.json               # Per-case result with plan_summary, coherence_details
├── go_grpc_circular_3_service_rename.json
└── ...
```

### Per-Case Result Fields

| Field | Description |
|-------|-------------|
| `passed` | Whether all `must_be_together` and `must_be_ordered` constraints were satisfied |
| `plan_summary` | The generated commit plan — commit IDs, types, titles, assigned hunks/files |
| `coherence_details` | Human-readable log of which constraints passed or failed |
| `input_tokens` | Prompt tokens consumed |
| `output_tokens` | Response tokens (actual plan output, excluding thinking) |
| `thinking_tokens` | Internal reasoning tokens (thinking models like Gemini 2.5) |
| `latency_seconds` | Wall-clock time for the LLM call |

### Summary Fields

| Field | Description |
|-------|-------------|
| `pass_rate` | Percentage of cases that passed |
| `results_by_language` | Pass/fail counts grouped by language |
| `results_by_difficulty` | Pass/fail counts grouped by difficulty |
| `results_by_category` | Pass/fail counts grouped by category |

---

## Adding New Test Cases

1. Create a new JSON file under `data/` following the schema above.
2. Use a descriptive filename: `<language>_<brief_description>.json`
3. Required fields: `id`, `language`, `name`, `description`, `difficulty`,
   `category`, `num_files`, `num_hunks`, `file_diffs`, `file_relationships`,
   `must_be_together`, `hunk_to_file`.
4. Optional field: `must_be_ordered` — list of `[dep_file, consumer_file]`
   pairs where the dependency must be committed at or before the consumer.
5. `file_diffs` must contain realistic unified diff content — the LLM reads
   the actual diff lines to understand the changes.
6. `file_relationships` should include the dependencies you expect
   Strategy 2 to detect (direct, transitive, or re-export).
7. `must_be_together` defines the **pass criteria**: which files must end up
   in the same commit for the codebase to remain valid.
8. Set `difficulty` based on scale:
   - `medium`: 2–3 files, straightforward rename/removal
   - `hard`: 3–4 files, transitive chains or multi-consumer
   - `very_hard`: 4–6 files, mixed features or interleaved groups
   - `super_hard`: 6–8 files, cascading renames with noise
   - `hyper_hard`: 20+ files, monorepo-scale refactors

### Auto-generating hyper_hard cases

For `hyper_hard` cases with 20+ files and 50+ hunks, use the generator script:

```bash
python scripts/generate_hyper_hard_cases.py
```

This creates JSON test cases with complex multi-level dependency chains,
circular references, and interleaved rename patterns.

---

## Design Decisions

### Why synthetic diffs instead of real repo diffs?

- **Reproducibility**: Real diffs change as the codebase evolves. Synthetic
  diffs produce identical prompts on every run.
- **Targeted testing**: Each case isolates a specific coherence challenge
  (e.g., transitive chains, re-exports, interleaved features).
- **Ground truth**: With synthetic diffs, we know *exactly* which files must
  be together — there is no ambiguity in the expected answer.

### Why live API calls instead of mocking?

The purpose of these tests is to evaluate how the LLM *actually behaves*
when given the coherence rules and file relationships. Mocking the LLM
response would test the evaluation harness, not the coherence strategy.

### Why `file_relationships` are pre-computed (not detected)?

The test cases provide synthetic file paths that don't exist on disk, so
`detect_file_relationships()` cannot read them. Instead, each test case
includes the expected relationships as they *would* be detected by
Strategy 2, and passes them directly to `build_compose_prompt()`.

### Token costs

A full run of all 27 cases with Gemini 2.5 Flash typically uses:
- ~27,000 input tokens
- ~3,000–5,000 output tokens
- ~40,000–50,000 thinking tokens (internal reasoning, lower cost tier)
- ~2–3 minutes total latency

